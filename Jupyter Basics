##  Creating variable - Single variable with single value
   ## With Data Type like Str, Int and Float
my_name = 'Abhishek'
print(my_name)
Abhishek
type(my_name)
str

marks = 98
print(marks)    
98
type(marks)
int

test_marks = 98.5
print(test_marks)
98.5
type(test_marks)
float

##  Boolean variables 
   ## Need to be created with capital T or F
Learning = True
print(Learning)
True
type(Learning)
bool
Sleeping = False
print(Sleeping)
False

## Creating Variables with None values
var = None
print(var)
None
type(var)
NoneType


## Collections in Python
my_list = [-1.1,'steve',my_name,Learning]
print(my_list)
[-1.1, 'steve', 'Abhishek', True]
print(my_list[1])
steve
## Desc - It is called as indexing and python assigns a index value to the individual element
    ## Referencing starts at 0 from left to right and from right to left starts at -1

my_list[1]
'steve'
## without the print command too we can get the same output
my_list[2]
'Abhishek'
my_list[3]
True

## Referencing starts from right to left starts at -1 and then it goes sequencing like , -2 and -3
my_list[-1]
True

## In case if we have to add any new value in the existing variable/List
## Putting a dot mean that we are giving a command to python that we are calling out a specific inbuilt functions.
## By hitting tab after some intital and dot, we can get options to choose inbuilt functions
my_list.append('Arjun')
my_list
[-1.1, 'steve', 'Abhishek', True, 'Arjun']
## Element gets added at the end of the list


## to remove any value from the list
my_list.remove (-1.1)
my_list
['steve', 'Abhishek', True, 'Arjun']
my_list.pop(1)
'Abhishek'
my_list
['steve', True, 'Arjun']


## Creating a copy of the variable
my_list2 = my_list.copy()
my_list2
['steve', True, 'Arjun']

## Clearing the entire list permanently
my_list2.clear()
my_list2
[]

## Array set of Data
x = [10,20,30,40]
y = [50,60,70,80]
x.append(100)
x
[10, 20, 30, 40, 100]

## Using extend will 
x.extend(y)
x
[10, 20, 30, 40, 100, 50, 60, 70, 80]
y
[50, 60, 70, 80]
x.append(y)
x
[10, 20, 30, 40, 100, 50, 60, 70, 80, [50, 60, 70, 80]]
x.pop(-1)
[50, 60, 70, 80]
x
[10, 20, 30, 40, 100, 50, 60, 70, 80]
x.sort()
x
[10, 20, 30, 40, 50, 60, 70, 80, 100]
x.sort(reverse = True)
x
[100, 80, 70, 60, 50, 40, 30, 20, 10]
new_var = [30,20,10,40,50]
new_var.sort()
new_var
[10, 20, 30, 40, 50]
new_var.sort(reverse=True)
new_var
[50, 40, 30, 20, 10]
var2 = ['apple','strawberry','banana']
var2.sort()
var2
['apple', 'banana', 'strawberry']
len(var2)
3
var3 = [10,20.5,11,15,14]
var3.sort()
var3
[10, 11, 14, 15, 20.5]
var4 = ['apple','amsterdam','bala','steve']
var4.sort()
var4
['amsterdam', 'apple', 'bala', 'steve']
var5 = [2,3,4,5,6]
var5*2
[2, 3, 4, 5, 6, 2, 3, 4, 5, 6]
print(var5)
for x in var5:
    var = x*2
    print(var)
    print("----")
[2, 3, 4, 5, 6]
4
----
6
----
8
----
10
----
12
----
2+3
5
User Defines functions in Python

def add_two_numbers (x,y):
    result = x+y
    print(result)
add_two_numbers(10,20)
30
add_two_numbers(2.6,4.5)
7.1
add_two_numbers('Steve','waugh')
Stevewaugh
add_two_numbers(4,-3)
1
4**2
16
def is_divisible(num,divisible_by):
    if num%divisible_by==0:
        print("it is divisible")
    else:
        print("it is not divisible")
is_divisible (20,3)
it is not divisible
is_divisible (21,3)
it is divisible
def assign_grades(marks):
    if marks < 100 and marks >= 90:
        print("Grade A")
    elif marks < 90 and marks >= 80:
        print("Grade B")
    else:
        print("Grade C")
    
assign_grades (85)
Grade B
assign_grades (80)
Grade B
assign_grades (95)
Grade A
assign_grades (65)
Grade C
student_marks = [60,75,85,95,100]
def assign_grades (marks):
    for marks in student_marks:
        if marks <=100 and marks >=90:
            print("Grade A")
        elif marks <90 and marks >=80:
            print("Grade B")
        else:
            print("Grade C")
assign_grades(student_marks)
Grade C
Grade C
Grade B
Grade A
Grade A
student_marks2 = [70,75,95,85,80]
assign_grades(student_marks2)
Grade C
Grade C
Grade B
Grade A
Grade A
def assign_grades (marks):
    for x in marks:
        if x <= 100 and x >= 90:
            print("Grade A")
        elif x <= 89 and x >= 80:
            print("Grade B")
        else:
            print("Grade C")
student_marks3 = [70,100,89,4,80,90]
assign_grades(student_marks3)
Grade C
Grade A
Grade B
Grade C
Grade B
Grade A
Collection in Python - Tuples
my_list = [20,25,36,40]
my_list[2]
36
my_list [2] =37
my_list
[20, 25, 37, 40]
my_tuple = ('Abhishek',30)
type(my_list)
list
type(my_tuple)
tuple
my_tuple[0]
'Abhishek'
my_tuple=('Abhishek',31)
customer_id = ('1001','1002','1002','1003')
customer_id.count('1001')
1
customer_id.count('1002')
2
len(customer_id)
4
values = [10,20,30,40.5,60]
for i in values:
    if i < 30:
        result = i + 50
        print(result)
60
70
values.index(40.5)
3
values[4]
60
values[-1]
60
customer_id = ('A1001','A1002','A1001','A1003')
customer_id.count('A1001')
2
my_dictionary = {'Name':'Abhishek','Age':30,'Gender':'Male'}
type(my_dictionary)
dict
my_dictionary['Name']
'Abhishek'
my_dictionary['Age']
30
my_dictionary.get('Gender')
'Male'
if we give search for 'Location', then there will be an error. Hence we can use not found option

my_dictionary.get('location','not found')
'not found'
my_dictionary.get('Name')
'Abhishek'
my_dictionary.keys()
dict_keys(['Name', 'Age', 'Gender'])
my_dictionary.values()
dict_values(['Abhishek', 30, 'Male'])
my_dictionary.items()
dict_items([('Name', 'Abhishek'), ('Age', 30), ('Gender', 'Male')])
for key, value in my_dictionary.items():
    print(key)
    print("----")
    print(value)
Name
----
Abhishek
Age
----
30
Gender
----
Male
for key, value in my_dictionary.items():
    print(key,value)
Name Abhishek
Age 30
Gender Male
len(my_dictionary)
3
employee_dictionary = {'Name':['Abhishek','Steve','Mark','Stella'],'Age':[30,40,50,45],'Gender':['Male','Male','Male','Female']}
employee_dictionary.get('Name')
['Abhishek', 'Steve', 'Mark', 'Stella']
for key,value in employee_dictionary.items():
    print(key,value[0])
Name Abhishek
Age 30
Gender Male
for key,value in employee_dictionary.items():
    print(key,value[2])
Name Mark
Age 50
Gender Male
for key,value in employee_dictionary.items():
    print(key,value[-1])
Name Stella
Age 45
Gender Female
updated_age = {'Age':[32,42,52,47]}

employee_dictionary.update(updated_age)
employee_dictionary
{'Name': ['Abhishek', 'Steve', 'Mark', 'Stella'],
 'Age': [32, 42, 52, 47],
 'Gender': ['Male', 'Male', 'Male', 'Female']}
employee_dictionary.update({'Location':['India','US','UK','Australia']})
employee_dictionary
{'Name': ['Abhishek', 'Steve', 'Mark', 'Stella'],
 'Age': [32, 42, 52, 47],
 'Gender': ['Male', 'Male', 'Male', 'Female'],
 'Location': ['India', 'US', 'UK', 'Australia']}
employee_dictionary.pop('Gender')
['Male', 'Male', 'Male', 'Female']
employee_dictionary
{'Name': ['Abhishek', 'Steve', 'Mark', 'Stella'],
 'Age': [32, 42, 52, 47],
 'Location': ['India', 'US', 'UK', 'Australia']}
employee_dictionary.popitem()
('Location', ['India', 'US', 'UK', 'Australia'])
employee_dictionary
{'Name': ['Abhishek', 'Steve', 'Mark', 'Stella'], 'Age': [32, 42, 52, 47]}
list1 = [10,20,30,40,50]
list2 = [30,40,50,60,70]
list1 + list2
[10, 20, 30, 40, 50, 30, 40, 50, 60, 70]
dict1 = {'numbers':[10,20,30,40,50]}
dict2 = {'numbers':[30,40,50,60,70]}
dict1 + dict2 , wont work and there will be error on Operand as two dictionaries cannot be merged together, Unless we use def or Merge functions

Downloading Library
import math as m
m.factorial(5)
120
m.floor(2.3)
2
m.ceil(2.3)
3
Python Packages
list1 = [10,20,30]
list2 = [40,50,60]
list1+ list2
[10, 20, 30, 40, 50, 60]
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
type(list1)
list
list1_new = np.array(list1)
type(list1_new)
numpy.ndarray
list2_new = np.array(list2)
type(list2_new)
numpy.ndarray
print(list1_new)
[10 20 30]
print(list2_new)
[40 50 60]
list1_new + list2_new
array([50, 70, 90])
list_of_list = [[10,11,12],[20,21,22],[30,31,32]]
np.array(list_of_list)
array([[10, 11, 12],
       [20, 21, 22],
       [30, 31, 32]])
np.arange(0,20)
array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,
       17, 18, 19])
np.arange(0,20,4)
array([ 0,  4,  8, 12, 16])
np.linspace(0,20)
array([ 0.        ,  0.40816327,  0.81632653,  1.2244898 ,  1.63265306,
        2.04081633,  2.44897959,  2.85714286,  3.26530612,  3.67346939,
        4.08163265,  4.48979592,  4.89795918,  5.30612245,  5.71428571,
        6.12244898,  6.53061224,  6.93877551,  7.34693878,  7.75510204,
        8.16326531,  8.57142857,  8.97959184,  9.3877551 ,  9.79591837,
       10.20408163, 10.6122449 , 11.02040816, 11.42857143, 11.83673469,
       12.24489796, 12.65306122, 13.06122449, 13.46938776, 13.87755102,
       14.28571429, 14.69387755, 15.10204082, 15.51020408, 15.91836735,
       16.32653061, 16.73469388, 17.14285714, 17.55102041, 17.95918367,
       18.36734694, 18.7755102 , 19.18367347, 19.59183673, 20.        ])
np.linspace(0,20,5)
array([ 0.,  5., 10., 15., 20.])
np.ones(5)
array([1., 1., 1., 1., 1.])
np.zeros(5)
array([0., 0., 0., 0., 0.])
np.eye(5)
array([[1., 0., 0., 0., 0.],
       [0., 1., 0., 0., 0.],
       [0., 0., 1., 0., 0.],
       [0., 0., 0., 1., 0.],
       [0., 0., 0., 0., 1.]])
np.random.randn(5)
array([-0.27215686, -0.97555754,  0.69194728,  2.02068444,  1.08933417])
var=np.random.randn(5)
type(var)
numpy.ndarray
np.random.randint(5,20)
15
np.random.randint(5,20,5)
array([ 7, 14,  6, 11,  7])
random_array = np.random.randint(0,100,20)
random_array
array([85, 26,  9, 35, 16, 15, 67, 60, 44,  2, 69, 53,  3, 84, 84, 55, 16,
       68, 28,  6])
len(random_array)
20
random_array.shape
(20,)
random_array_new = random_array.reshape(4,5)
random_array_new.shape
(4, 5)
random_array
array([85, 26,  9, 35, 16, 15, 67, 60, 44,  2, 69, 53,  3, 84, 84, 55, 16,
       68, 28,  6])
random_array[4]
16
random_array[-1]
6
random_array.max()
85
random_array.min()
2
random_array.argmax()
0
random_array.argmin()
9
random_array.mean()
41.25
random_array.std()
28.37406386120959
random_array.var()
805.0875
random_array
array([85, 26,  9, 35, 16, 15, 67, 60, 44,  2, 69, 53,  3, 84, 84, 55, 16,
       68, 28,  6])
random_array[3]
35
random_array[0:4]
array([85, 26,  9, 35])
random_array[[0,4,7]]
array([85, 16, 60])
random_array_new
array([[85, 26,  9, 35, 16],
       [15, 67, 60, 44,  2],
       [69, 53,  3, 84, 84],
       [55, 16, 68, 28,  6]])
random_array_new[1]
array([15, 67, 60, 44,  2])
random_array_new[1,2]
60
random_array_new[2,-1]
84
random_array_new[1:3,2:5]
array([[60, 44,  2],
       [ 3, 84, 84]])
random_array_new[2:4,2:5]
array([[ 3, 84, 84],
       [68, 28,  6]])
random_array_new[:,1]
array([26, 67, 53, 16])
random_array_new
array([[85, 26,  9, 35, 16],
       [15, 67, 60, 44,  2],
       [69, 53,  3, 84, 84],
       [55, 16, 68, 28,  6]])
random_array_new[:,4]
array([16,  2, 84,  6])
random_array
array([85, 26,  9, 35, 16, 15, 67, 60, 44,  2, 69, 53,  3, 84, 84, 55, 16,
       68, 28,  6])
random_array < 50
array([False,  True,  True,  True,  True,  True, False, False,  True,
        True, False, False,  True, False, False, False,  True, False,
        True,  True])
random_array[random_array < 50]
array([26,  9, 35, 16, 15, 44,  2,  3, 16, 28,  6])
random_array[(random_array < 50) & (random_array > 25)]
array([26, 35, 44, 28])
random_array[(random_array < 50) | (random_array > 25)]
array([85, 26,  9, 35, 16, 15, 67, 60, 44,  2, 69, 53,  3, 84, 84, 55, 16,
       68, 28,  6])
random_array[(random_array < 30) | (random_array > 85)]
array([26,  9, 16, 15,  2,  3, 16, 28,  6])
np.sqrt(random_array)
array([9.21954446, 5.09901951, 3.        , 5.91607978, 4.        ,
       3.87298335, 8.18535277, 7.74596669, 6.63324958, 1.41421356,
       8.30662386, 7.28010989, 1.73205081, 9.16515139, 9.16515139,
       7.41619849, 4.        , 8.24621125, 5.29150262, 2.44948974])
np.exp(random_array)
array([8.22301271e+36, 1.95729609e+11, 8.10308393e+03, 1.58601345e+15,
       8.88611052e+06, 3.26901737e+06, 1.25236317e+29, 1.14200739e+26,
       1.28516001e+19, 7.38905610e+00, 9.25378173e+29, 1.04137594e+23,
       2.00855369e+01, 3.02507732e+36, 3.02507732e+36, 7.69478527e+23,
       8.88611052e+06, 3.40427605e+29, 1.44625706e+12, 4.03428793e+02])
random_array.pop('o'), 'numpy.ndarray' object has no attribute 'pop'

np.log(random_array)
array([4.44265126, 3.25809654, 2.19722458, 3.55534806, 2.77258872,
       2.7080502 , 4.20469262, 4.09434456, 3.78418963, 0.69314718,
       4.2341065 , 3.97029191, 1.09861229, 4.4308168 , 4.4308168 ,
       4.00733319, 2.77258872, 4.21950771, 3.33220451, 1.79175947])
np.cos(random_array)
array([-0.98437664,  0.64691932, -0.91113026, -0.90369221, -0.95765948,
       -0.75968791, -0.5177698 , -0.95241298,  0.99984331, -0.41614684,
        0.99339038, -0.91828279, -0.9899925 , -0.6800235 , -0.6800235 ,
        0.02212676, -0.95765948,  0.44014302, -0.96260587,  0.96017029])
np.round(np.cos(random_array),decimals=2)
array([-0.98,  0.65, -0.91, -0.9 , -0.96, -0.76, -0.52, -0.95,  1.  ,
       -0.42,  0.99, -0.92, -0.99, -0.68, -0.68,  0.02, -0.96,  0.44,
       -0.96,  0.96])
my_list = [10,20,30,40]
labels = ['w','x','y','z']
my_array =np.array(my_list)
my_array
array([10, 20, 30, 40])
my_array[2]
30
pd.Series(data=my_list)
0    10
1    20
2    30
3    40
dtype: int64
pd.Series(data=my_list,index=labels)
w    10
x    20
y    30
z    40
dtype: int64
var = pd.Series(data=my_list,index=labels)
var[1]
20
var['x']
20
type(var)
pandas.core.series.Series
n_students = [5,3,2,7]
sports_name = ['Cricket','Football','Basketball','Golf']
sports_data1 = pd.Series(data=n_students,index=sports_name)
sports_data1
Cricket       5
Football      3
Basketball    2
Golf          7
dtype: int64
sports_data1['Football']
3
n_students_2 = [4,6,3,5]
sports_name_2 = ['Cricket','Tennis','Football','Badminton']
sports_data2 = pd.Series(data=n_students_2,index=sports_name_2)
sports_data2
Cricket      4
Tennis       6
Football     3
Badminton    5
dtype: int64
sports_data1 + sports_data2
Badminton     NaN
Basketball    NaN
Cricket       9.0
Football      6.0
Golf          NaN
Tennis        NaN
dtype: float64
Data Frames
sample_df = pd.DataFrame(data=np.random.randn(10,5))
sample_df
0	1	2	3	4
0	1.035804	2.174704	-0.248380	0.609632	-1.187387
1	-0.398505	0.262003	1.646161	0.187757	0.318687
2	0.083800	1.999111	-0.183022	-0.685034	-0.138202
3	0.131076	-1.750361	1.553291	1.480318	1.059114
4	-0.003787	0.031709	-0.695844	1.957349	0.771475
5	-0.222772	0.318391	0.335503	-0.554743	-1.888000
6	0.326715	-0.383917	1.075342	0.123106	0.569280
7	0.642950	-0.871716	-1.430804	-1.001057	-0.200109
8	-0.032568	0.714623	2.590849	-0.320028	-1.111285
9	-0.254065	0.803209	-0.939384	0.918889	0.688427
sample_df = pd.DataFrame(data=np.random.randn(10,5),index='A B C D E F G H I J'.split())
sample_df
0	1	2	3	4
A	0.213539	1.488226	-0.743074	-0.676643	-0.471187
B	-0.036535	-0.617644	-2.916069	0.049793	-0.259413
C	-0.974687	-0.449859	-2.318767	0.452279	0.883226
D	0.519245	-0.320568	-0.919303	0.928864	-0.991679
E	1.412642	0.114588	-1.135514	0.612150	0.304547
F	0.768667	-0.884736	0.055300	-1.202058	0.223725
G	0.436830	0.034765	1.053684	-0.301734	-0.205483
H	-1.154191	-0.859887	-1.165490	-1.627691	0.307616
I	-0.959224	-0.760097	-0.570663	0.755117	1.189762
J	-0.622444	1.589029	-0.560890	-0.902156	-0.641053
sample_df = pd.DataFrame(data=np.random.randn(10,5),index='A B C D E F G H I J'.split(),columns='score1 score2 score3 score4 score5'.split())
sample_df
score1	score2	score3	score4	score5
A	-0.554322	1.367172	2.119192	-2.971954	0.529909
B	0.025652	0.317792	0.051008	-1.033735	0.312093
C	0.211045	0.585038	0.549660	0.051287	-0.701133
D	-0.544421	0.739545	-1.351503	0.470789	-0.672292
E	0.857665	-0.768950	-0.786824	1.599637	-0.417101
F	-0.320256	-0.535751	-1.089605	-1.032817	-0.184715
G	1.760843	-0.114394	1.187818	0.500333	-0.640486
H	-0.162462	-0.075124	-0.965279	1.359424	-0.294909
I	0.431573	-0.674872	-0.417201	-0.835287	-0.040618
J	-0.425894	1.116172	-0.554816	-0.088739	-0.718549
sample_df['score3']
A    2.119192
B    0.051008
C    0.549660
D   -1.351503
E   -0.786824
F   -1.089605
G    1.187818
H   -0.965279
I   -0.417201
J   -0.554816
Name: score3, dtype: float64
sample_df[['score3','score5']]
score3	score5
A	2.119192	0.529909
B	0.051008	0.312093
C	0.549660	-0.701133
D	-1.351503	-0.672292
E	-0.786824	-0.417101
F	-1.089605	-0.184715
G	1.187818	-0.640486
H	-0.965279	-0.294909
I	-0.417201	-0.040618
J	-0.554816	-0.718549
var = sample_df['score3']
type(var)
pandas.core.series.Series
var2= sample_df[['score3','score5']]
type(var2)
pandas.core.frame.DataFrame
sample_df['score6'] = sample_df['score1'] + sample_df['score2']
sample_df['score6']
A    0.812849
B    0.343444
C    0.796082
D    0.195125
E    0.088715
F   -0.856008
G    1.646449
H   -0.237586
I   -0.243299
J    0.690279
Name: score6, dtype: float64
sample_df
score1	score2	score3	score4	score5	score6
A	-0.554322	1.367172	2.119192	-2.971954	0.529909	0.812849
B	0.025652	0.317792	0.051008	-1.033735	0.312093	0.343444
C	0.211045	0.585038	0.549660	0.051287	-0.701133	0.796082
D	-0.544421	0.739545	-1.351503	0.470789	-0.672292	0.195125
E	0.857665	-0.768950	-0.786824	1.599637	-0.417101	0.088715
F	-0.320256	-0.535751	-1.089605	-1.032817	-0.184715	-0.856008
G	1.760843	-0.114394	1.187818	0.500333	-0.640486	1.646449
H	-0.162462	-0.075124	-0.965279	1.359424	-0.294909	-0.237586
I	0.431573	-0.674872	-0.417201	-0.835287	-0.040618	-0.243299
J	-0.425894	1.116172	-0.554816	-0.088739	-0.718549	0.690279
sample_df.drop('score6',axis=1)
score1	score2	score3	score4	score5
A	-0.554322	1.367172	2.119192	-2.971954	0.529909
B	0.025652	0.317792	0.051008	-1.033735	0.312093
C	0.211045	0.585038	0.549660	0.051287	-0.701133
D	-0.544421	0.739545	-1.351503	0.470789	-0.672292
E	0.857665	-0.768950	-0.786824	1.599637	-0.417101
F	-0.320256	-0.535751	-1.089605	-1.032817	-0.184715
G	1.760843	-0.114394	1.187818	0.500333	-0.640486
H	-0.162462	-0.075124	-0.965279	1.359424	-0.294909
I	0.431573	-0.674872	-0.417201	-0.835287	-0.040618
J	-0.425894	1.116172	-0.554816	-0.088739	-0.718549
sample_df
score1	score2	score3	score4	score5	score6
A	-0.554322	1.367172	2.119192	-2.971954	0.529909	0.812849
B	0.025652	0.317792	0.051008	-1.033735	0.312093	0.343444
C	0.211045	0.585038	0.549660	0.051287	-0.701133	0.796082
D	-0.544421	0.739545	-1.351503	0.470789	-0.672292	0.195125
E	0.857665	-0.768950	-0.786824	1.599637	-0.417101	0.088715
F	-0.320256	-0.535751	-1.089605	-1.032817	-0.184715	-0.856008
G	1.760843	-0.114394	1.187818	0.500333	-0.640486	1.646449
H	-0.162462	-0.075124	-0.965279	1.359424	-0.294909	-0.237586
I	0.431573	-0.674872	-0.417201	-0.835287	-0.040618	-0.243299
J	-0.425894	1.116172	-0.554816	-0.088739	-0.718549	0.690279
axis=1 is for column and axis = 0 is for rows It does not remove Score 6 permanently, but if you wish to remove permanently

sample_df.drop('score6',axis=1, inplace=True)
sample_df
score1	score2	score3	score4	score5
A	-0.554322	1.367172	2.119192	-2.971954	0.529909
B	0.025652	0.317792	0.051008	-1.033735	0.312093
C	0.211045	0.585038	0.549660	0.051287	-0.701133
D	-0.544421	0.739545	-1.351503	0.470789	-0.672292
E	0.857665	-0.768950	-0.786824	1.599637	-0.417101
F	-0.320256	-0.535751	-1.089605	-1.032817	-0.184715
G	1.760843	-0.114394	1.187818	0.500333	-0.640486
H	-0.162462	-0.075124	-0.965279	1.359424	-0.294909
I	0.431573	-0.674872	-0.417201	-0.835287	-0.040618
J	-0.425894	1.116172	-0.554816	-0.088739	-0.718549
sample_df.loc['F']
score1   -0.320256
score2   -0.535751
score3   -1.089605
score4   -1.032817
score5   -0.184715
Name: F, dtype: float64
var3 = sample_df.loc['F']
type(var3)
pandas.core.series.Series
sample_df.iloc[2]
score1    0.211045
score2    0.585038
score3    0.549660
score4    0.051287
score5   -0.701133
Name: C, dtype: float64
sample_df.loc['A','score3']
2.119191675819555
sample_df.loc['F','score5']
-0.18471454877706797
sample_df.iloc[0:2,2:4]
score3	score4
A	2.119192	-2.971954
B	0.051008	-1.033735
sample_df.loc[['A','B'],['score3','score4']]
score3	score4
A	2.119192	-2.971954
B	0.051008	-1.033735
sample_df
score1	score2	score3	score4	score5
A	-0.554322	1.367172	2.119192	-2.971954	0.529909
B	0.025652	0.317792	0.051008	-1.033735	0.312093
C	0.211045	0.585038	0.549660	0.051287	-0.701133
D	-0.544421	0.739545	-1.351503	0.470789	-0.672292
E	0.857665	-0.768950	-0.786824	1.599637	-0.417101
F	-0.320256	-0.535751	-1.089605	-1.032817	-0.184715
G	1.760843	-0.114394	1.187818	0.500333	-0.640486
H	-0.162462	-0.075124	-0.965279	1.359424	-0.294909
I	0.431573	-0.674872	-0.417201	-0.835287	-0.040618
J	-0.425894	1.116172	-0.554816	-0.088739	-0.718549
sample_df.iloc[4:7,2:5]
score3	score4	score5
E	-0.786824	1.599637	-0.417101
F	-1.089605	-1.032817	-0.184715
G	1.187818	0.500333	-0.640486
sample_df.loc[['E','F','G'],['score3','score4','score5']]
score3	score4	score5
E	-0.786824	1.599637	-0.417101
F	-1.089605	-1.032817	-0.184715
G	1.187818	0.500333	-0.640486
sample_df > 0.5
score1	score2	score3	score4	score5
A	False	True	True	False	True
B	False	False	False	False	False
C	False	True	True	False	False
D	False	True	False	False	False
E	True	False	False	True	False
F	False	False	False	False	False
G	True	False	True	True	False
H	False	False	False	True	False
I	False	False	False	False	False
J	False	True	False	False	False
sample_df[sample_df > 0.5]
score1	score2	score3	score4	score5
A	NaN	1.367172	2.119192	NaN	0.529909
B	NaN	NaN	NaN	NaN	NaN
C	NaN	0.585038	0.549660	NaN	NaN
D	NaN	0.739545	NaN	NaN	NaN
E	0.857665	NaN	NaN	1.599637	NaN
F	NaN	NaN	NaN	NaN	NaN
G	1.760843	NaN	1.187818	0.500333	NaN
H	NaN	NaN	NaN	1.359424	NaN
I	NaN	NaN	NaN	NaN	NaN
J	NaN	1.116172	NaN	NaN	NaN
sample_df[sample_df['score1']>.5]
score1	score2	score3	score4	score5
E	0.857665	-0.768950	-0.786824	1.599637	-0.417101
G	1.760843	-0.114394	1.187818	0.500333	-0.640486
sample_df[sample_df['score1']>0.5]['score5']
E   -0.417101
G   -0.640486
Name: score5, dtype: float64
sample_df[sample_df['score1']>0.5][['score3','score5']]
score3	score5
E	-0.786824	-0.417101
G	1.187818	-0.640486
sample_df[sample_df['score1']>0.5]['score5']>0.5
E    False
G    False
Name: score5, dtype: bool
sample_df[(sample_df['score1']>0.3) & (sample_df['score3']> 0.1)]
score1	score2	score3	score4	score5
G	1.760843	-0.114394	1.187818	0.500333	-0.640486
sample_df[(sample_df['score1']>0.5) | (sample_df['score3']>0.2)]
score1	score2	score3	score4	score5
A	-0.554322	1.367172	2.119192	-2.971954	0.529909
C	0.211045	0.585038	0.549660	0.051287	-0.701133
E	0.857665	-0.768950	-0.786824	1.599637	-0.417101
G	1.760843	-0.114394	1.187818	0.500333	-0.640486
sample_df[(sample_df['score1']>0.5) | (sample_df['score3']>0.2)][['score3','score4']]
score3	score4
A	2.119192	-2.971954
C	0.549660	0.051287
E	-0.786824	1.599637
G	1.187818	0.500333
When the Data is continous, we can use mean to replace null values, when the Data is discrete thena we can use mean/median to replace null values, when the data is categorical, we can use mode to replace the null values

sports_data = {'cricket':[1,2,np.nan,4,6,7],'Tennis':[5,np.nan,2,np.nan,4,7]}
sports_df = pd.DataFrame(sports_data)
sports_df
cricket	Tennis
0	1.0	5.0
1	2.0	NaN
2	NaN	2.0
3	4.0	NaN
4	6.0	4.0
5	7.0	7.0
sports_df['cricket'].fillna(value=sports_df['cricket'].mean())
0    1.0
1    2.0
2    4.0
3    4.0
4    6.0
5    7.0
Name: cricket, dtype: float64
sports_df['Tennis'].fillna(value=sports_df['Tennis'].mean())
0    5.0
1    4.5
2    2.0
3    4.5
4    4.0
5    7.0
Name: Tennis, dtype: float64
sports_df
cricket	Tennis
0	1.0	5.0
1	2.0	NaN
2	NaN	2.0
3	4.0	NaN
4	6.0	4.0
5	7.0	7.0
sports_df['cricket'] = sports_df['cricket'].fillna(value=sports_df['cricket'].mean())
sports_df['Tennis'] = sports_df['Tennis'].fillna(value=sports_df['Tennis'].mean())
sports_df
cricket	Tennis
0	1.0	5.0
1	2.0	4.5
2	4.0	2.0
3	4.0	4.5
4	6.0	4.0
5	7.0	7.0
Python Operations
height_weight_df = pd.read_csv(r"C:\Users\Abhishek\OneDrive\Documents\Data Scientist\Class Notes\Python\Datasets\height-weight.csv")
type(height_weight_df)
pandas.core.frame.DataFrame
height_weight_df.shape
(25000, 3)
height_weight_df.size
75000
height_weight_df.head()
Index	Height(Inches)	Weight(Pounds)
0	1	65.78331	112.9925
1	2	71.51521	136.4873
2	3	69.39874	153.0269
3	4	68.21660	142.3354
4	5	67.78781	144.2971
height_weight_df.head(2)
Index	Height(Inches)	Weight(Pounds)
0	1	65.78331	112.9925
1	2	71.51521	136.4873
height_weight_df.tail()
Index	Height(Inches)	Weight(Pounds)
24995	24996	69.50215	118.0312
24996	24997	64.54826	120.1932
24997	24998	64.69855	118.2655
24998	24999	67.52918	132.2682
24999	25000	68.87761	124.8742
height_weight_df.tail(2)
Index	Height(Inches)	Weight(Pounds)
24998	24999	67.52918	132.2682
24999	25000	68.87761	124.8742
height_weight_df.columns
Index(['Index', 'Height(Inches)', 'Weight(Pounds)'], dtype='object')
height_weight_df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 25000 entries, 0 to 24999
Data columns (total 3 columns):
 #   Column          Non-Null Count  Dtype  
---  ------          --------------  -----  
 0   Index           25000 non-null  int64  
 1   Height(Inches)  25000 non-null  float64
 2   Weight(Pounds)  25000 non-null  float64
dtypes: float64(2), int64(1)
memory usage: 586.1 KB
height_weight_df['height'] = height_weight_df['Height(Inches)'].map(lambda inches: round(inches*0.083,2))
height_weight_df.head()
Index	Height(Inches)	Weight(Pounds)	height
0	1	65.78331	112.9925	5.46
1	2	71.51521	136.4873	5.94
2	3	69.39874	153.0269	5.76
3	4	68.21660	142.3354	5.66
4	5	67.78781	144.2971	5.63
height_weight_df['weight'] = height_weight_df['Weight(Pounds)'].map(lambda pounds: round(pounds*0.4535,2))
height_weight_df.head()
Index	Height(Inches)	Weight(Pounds)	height	weight
0	1	65.78331	112.9925	5.46	51.24
1	2	71.51521	136.4873	5.94	61.90
2	3	69.39874	153.0269	5.76	69.40
3	4	68.21660	142.3354	5.66	64.55
4	5	67.78781	144.2971	5.63	65.44
final_df = height_weight_df.iloc[:,3:5]
final_df.head()
height	weight
0	5.46	51.24
1	5.94	61.90
2	5.76	69.40
3	5.66	64.55
4	5.63	65.44
import matplotlib.pyplot as plt
plt.scatter(x,y) - plotting a scatter graph
plt.scatter(final_df['height'],final_df['weight'])
<matplotlib.collections.PathCollection at 0x1634ae8eeb0>

plt.scatter(final_df['height'],final_df['weight'])
plt.xlabel('Height (in feet)')
plt.ylabel('Weight ( in kg)')
plt.title('Height - Weight Reltionship Study')
plt.show()

plt hist(x) - plotting a histogram chart for x
plt.hist(final_df['height'])
(array([   9.,  123., 1032., 3155., 6372., 7820., 4425., 1756.,  275.,
          33.]),
 array([5.   , 5.124, 5.248, 5.372, 5.496, 5.62 , 5.744, 5.868, 5.992,
        6.116, 6.24 ]),
 <BarContainer object of 10 artists>)

plt.hist(final_df['weight'])
(array([  13.,  112.,  758., 2951., 6392., 7673., 4996., 1712.,  359.,
          34.]),
 array([35.38 , 39.593, 43.806, 48.019, 52.232, 56.445, 60.658, 64.871,
        69.084, 73.297, 77.51 ]),
 <BarContainer object of 10 artists>)

visualization of housing Prices datasets
housing_df = pd.read_csv(r"C:\Users\Abhishek\OneDrive\Documents\Data Scientist\Class Notes\Python\Datasets\housing_prices.csv")
housing_df.shape
(1460, 81)
housing_df.columns
Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',
       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',
       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',
       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',
       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',
       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',
       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',
       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',
       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',
       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',
       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',
       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',
       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',
       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',
       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',
       'SaleCondition', 'SalePrice'],
      dtype='object')
housing_df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 1460 entries, 0 to 1459
Data columns (total 81 columns):
 #   Column         Non-Null Count  Dtype  
---  ------         --------------  -----  
 0   Id             1460 non-null   int64  
 1   MSSubClass     1460 non-null   int64  
 2   MSZoning       1460 non-null   object 
 3   LotFrontage    1201 non-null   float64
 4   LotArea        1460 non-null   int64  
 5   Street         1460 non-null   object 
 6   Alley          91 non-null     object 
 7   LotShape       1460 non-null   object 
 8   LandContour    1460 non-null   object 
 9   Utilities      1460 non-null   object 
 10  LotConfig      1460 non-null   object 
 11  LandSlope      1460 non-null   object 
 12  Neighborhood   1460 non-null   object 
 13  Condition1     1460 non-null   object 
 14  Condition2     1460 non-null   object 
 15  BldgType       1460 non-null   object 
 16  HouseStyle     1460 non-null   object 
 17  OverallQual    1460 non-null   int64  
 18  OverallCond    1460 non-null   int64  
 19  YearBuilt      1460 non-null   int64  
 20  YearRemodAdd   1460 non-null   int64  
 21  RoofStyle      1460 non-null   object 
 22  RoofMatl       1460 non-null   object 
 23  Exterior1st    1460 non-null   object 
 24  Exterior2nd    1460 non-null   object 
 25  MasVnrType     1452 non-null   object 
 26  MasVnrArea     1452 non-null   float64
 27  ExterQual      1460 non-null   object 
 28  ExterCond      1460 non-null   object 
 29  Foundation     1460 non-null   object 
 30  BsmtQual       1423 non-null   object 
 31  BsmtCond       1423 non-null   object 
 32  BsmtExposure   1422 non-null   object 
 33  BsmtFinType1   1423 non-null   object 
 34  BsmtFinSF1     1460 non-null   int64  
 35  BsmtFinType2   1422 non-null   object 
 36  BsmtFinSF2     1460 non-null   int64  
 37  BsmtUnfSF      1460 non-null   int64  
 38  TotalBsmtSF    1460 non-null   int64  
 39  Heating        1460 non-null   object 
 40  HeatingQC      1460 non-null   object 
 41  CentralAir     1460 non-null   object 
 42  Electrical     1459 non-null   object 
 43  1stFlrSF       1460 non-null   int64  
 44  2ndFlrSF       1460 non-null   int64  
 45  LowQualFinSF   1460 non-null   int64  
 46  GrLivArea      1460 non-null   int64  
 47  BsmtFullBath   1460 non-null   int64  
 48  BsmtHalfBath   1460 non-null   int64  
 49  FullBath       1460 non-null   int64  
 50  HalfBath       1460 non-null   int64  
 51  BedroomAbvGr   1460 non-null   int64  
 52  KitchenAbvGr   1460 non-null   int64  
 53  KitchenQual    1460 non-null   object 
 54  TotRmsAbvGrd   1460 non-null   int64  
 55  Functional     1460 non-null   object 
 56  Fireplaces     1460 non-null   int64  
 57  FireplaceQu    770 non-null    object 
 58  GarageType     1379 non-null   object 
 59  GarageYrBlt    1379 non-null   float64
 60  GarageFinish   1379 non-null   object 
 61  GarageCars     1460 non-null   int64  
 62  GarageArea     1460 non-null   int64  
 63  GarageQual     1379 non-null   object 
 64  GarageCond     1379 non-null   object 
 65  PavedDrive     1460 non-null   object 
 66  WoodDeckSF     1460 non-null   int64  
 67  OpenPorchSF    1460 non-null   int64  
 68  EnclosedPorch  1460 non-null   int64  
 69  3SsnPorch      1460 non-null   int64  
 70  ScreenPorch    1460 non-null   int64  
 71  PoolArea       1460 non-null   int64  
 72  PoolQC         7 non-null      object 
 73  Fence          281 non-null    object 
 74  MiscFeature    54 non-null     object 
 75  MiscVal        1460 non-null   int64  
 76  MoSold         1460 non-null   int64  
 77  YrSold         1460 non-null   int64  
 78  SaleType       1460 non-null   object 
 79  SaleCondition  1460 non-null   object 
 80  SalePrice      1460 non-null   int64  
dtypes: float64(3), int64(35), object(43)
memory usage: 924.0+ KB
plt.hist(housing_df['LotArea'])
(array([1.423e+03, 2.400e+01, 8.000e+00, 1.000e+00, 0.000e+00, 1.000e+00,
        0.000e+00, 2.000e+00, 0.000e+00, 1.000e+00]),
 array([  1300. ,  22694.5,  44089. ,  65483.5,  86878. , 108272.5,
        129667. , 151061.5, 172456. , 193850.5, 215245. ]),
 <BarContainer object of 10 artists>)

plt.boxplot(housing_df['LotArea'])
{'whiskers': [<matplotlib.lines.Line2D at 0x1634c7901c0>,
  <matplotlib.lines.Line2D at 0x1634c790490>],
 'caps': [<matplotlib.lines.Line2D at 0x1634c790820>,
  <matplotlib.lines.Line2D at 0x1634c790a30>],
 'boxes': [<matplotlib.lines.Line2D at 0x1634c77feb0>],
 'medians': [<matplotlib.lines.Line2D at 0x1634c790d00>],
 'fliers': [<matplotlib.lines.Line2D at 0x1634c790fd0>],
 'means': []}

plt.scatter(housing_df['LotArea'],housing_df['SalePrice'])
<matplotlib.collections.PathCollection at 0x1634b59b760>

plt.bar(housing_df['Exterior1st'],housing_df['Exterior1st'].values)
<BarContainer object of 1460 artists>

plt.bar(housing_df['Exterior1st'],housing_df['Exterior1st'].values,width=0.4)
<BarContainer object of 1460 artists>

movies_df = pd.read_csv(r"C:\Users\Abhishek\OneDrive\Documents\Data Scientist\Class Notes\Python\Datasets\movie_metadata.csv")
movies_df.shape
(5043, 28)
movies_df.columns
Index(['color', 'director_name', 'num_critic_for_reviews', 'duration',
       'director_facebook_likes', 'actor_3_facebook_likes', 'actor_2_name',
       'actor_1_facebook_likes', 'gross', 'genres', 'actor_1_name',
       'movie_title', 'num_voted_users', 'cast_total_facebook_likes',
       'actor_3_name', 'facenumber_in_poster', 'plot_keywords',
       'movie_imdb_link', 'num_user_for_reviews', 'language', 'country',
       'content_rating', 'budget', 'title_year', 'actor_2_facebook_likes',
       'imdb_score', 'aspect_ratio', 'movie_facebook_likes'],
      dtype='object')
movies_df.describe()
num_critic_for_reviews	duration	director_facebook_likes	actor_3_facebook_likes	actor_1_facebook_likes	gross	num_voted_users	cast_total_facebook_likes	facenumber_in_poster	num_user_for_reviews	budget	title_year	actor_2_facebook_likes	imdb_score	aspect_ratio	movie_facebook_likes
count	4993.000000	5028.000000	4939.000000	5020.000000	5036.000000	4.159000e+03	5.043000e+03	5043.000000	5030.000000	5022.000000	4.551000e+03	4935.000000	5030.000000	5043.000000	4714.000000	5043.000000
mean	140.194272	107.201074	686.509212	645.009761	6560.047061	4.846841e+07	8.366816e+04	9699.063851	1.371173	272.770808	3.975262e+07	2002.470517	1651.754473	6.442138	2.220403	7525.964505
std	121.601675	25.197441	2813.328607	1665.041728	15020.759120	6.845299e+07	1.384853e+05	18163.799124	2.013576	377.982886	2.061149e+08	12.474599	4042.438863	1.125116	1.385113	19320.445110
min	1.000000	7.000000	0.000000	0.000000	0.000000	1.620000e+02	5.000000e+00	0.000000	0.000000	1.000000	2.180000e+02	1916.000000	0.000000	1.600000	1.180000	0.000000
25%	50.000000	93.000000	7.000000	133.000000	614.000000	5.340988e+06	8.593500e+03	1411.000000	0.000000	65.000000	6.000000e+06	1999.000000	281.000000	5.800000	1.850000	0.000000
50%	110.000000	103.000000	49.000000	371.500000	988.000000	2.551750e+07	3.435900e+04	3090.000000	1.000000	156.000000	2.000000e+07	2005.000000	595.000000	6.600000	2.350000	166.000000
75%	195.000000	118.000000	194.500000	636.000000	11000.000000	6.230944e+07	9.630900e+04	13756.500000	2.000000	326.000000	4.500000e+07	2011.000000	918.000000	7.200000	2.350000	3000.000000
max	813.000000	511.000000	23000.000000	23000.000000	640000.000000	7.605058e+08	1.689764e+06	656730.000000	43.000000	5060.000000	1.221550e+10	2016.000000	137000.000000	9.500000	16.000000	349000.000000
Check Missing Values
movies_df.isnull().sum()
color                         19
director_name                104
num_critic_for_reviews        50
duration                      15
director_facebook_likes      104
actor_3_facebook_likes        23
actor_2_name                  13
actor_1_facebook_likes         7
gross                        884
genres                         0
actor_1_name                   7
movie_title                    0
num_voted_users                0
cast_total_facebook_likes      0
actor_3_name                  23
facenumber_in_poster          13
plot_keywords                153
movie_imdb_link                0
num_user_for_reviews          21
language                      12
country                        5
content_rating               303
budget                       492
title_year                   108
actor_2_facebook_likes        13
imdb_score                     0
aspect_ratio                 329
movie_facebook_likes           0
dtype: int64
movies_df['budget'].fillna(value=movies_df['budget'].mean(),inplace=True)
movies_df.isnull().sum()
color                         19
director_name                104
num_critic_for_reviews        50
duration                      15
director_facebook_likes      104
actor_3_facebook_likes        23
actor_2_name                  13
actor_1_facebook_likes         7
gross                        884
genres                         0
actor_1_name                   7
movie_title                    0
num_voted_users                0
cast_total_facebook_likes      0
actor_3_name                  23
facenumber_in_poster          13
plot_keywords                153
movie_imdb_link                0
num_user_for_reviews          21
language                      12
country                        5
content_rating               303
budget                         0
title_year                   108
actor_2_facebook_likes        13
imdb_score                     0
aspect_ratio                 329
movie_facebook_likes           0
dtype: int64
movies_df['gross'].fillna(value=movies_df['gross'].mean(),inplace=True)
movies_df.isnull().sum()
color                         19
director_name                104
num_critic_for_reviews        50
duration                      15
director_facebook_likes      104
actor_3_facebook_likes        23
actor_2_name                  13
actor_1_facebook_likes         7
gross                          0
genres                         0
actor_1_name                   7
movie_title                    0
num_voted_users                0
cast_total_facebook_likes      0
actor_3_name                  23
facenumber_in_poster          13
plot_keywords                153
movie_imdb_link                0
num_user_for_reviews          21
language                      12
country                        5
content_rating               303
budget                         0
title_year                   108
actor_2_facebook_likes        13
imdb_score                     0
aspect_ratio                 329
movie_facebook_likes           0
dtype: int64
movies_df.isnull().sum().sum()
1322
movies_df['language'].isnull().sum()
12
movies_df['language'].fillna(value='no info',inplace=True)
movies_df['language'].isnull().sum()
0
movies_df['director_name'].fillna(value='no info',inplace=True)
movies_df['director_name'].isnull().sum()
0
Check and Remove for Duplicated Records
duplicated_rows_df = movies_df[movies_df.duplicated()]
duplicated_rows_df.shape
(45, 28)
duplicated_rows_df.head()
color	director_name	num_critic_for_reviews	duration	director_facebook_likes	actor_3_facebook_likes	actor_2_name	actor_1_facebook_likes	gross	genres	...	num_user_for_reviews	language	country	content_rating	budget	title_year	actor_2_facebook_likes	imdb_score	aspect_ratio	movie_facebook_likes
137	Color	David Yates	248.0	110.0	282.0	103.0	Alexander Skarsgård	11000.0	1.240518e+08	Action|Adventure|Drama|Romance	...	239.0	English	USA	PG-13	1.800000e+08	2016.0	10000.0	6.6	2.35	29000
187	Color	Bill Condon	322.0	115.0	386.0	12000.0	Kristen Stewart	21000.0	2.922989e+08	Adventure|Drama|Fantasy|Romance	...	329.0	English	USA	PG-13	1.200000e+08	2012.0	17000.0	5.5	2.35	65000
204	Color	Hideaki Anno	1.0	120.0	28.0	12.0	Shin'ya Tsukamoto	544.0	4.846841e+07	Action|Adventure|Drama|Horror|Sci-Fi	...	13.0	Japanese	Japan	NaN	3.975262e+07	2016.0	106.0	8.2	2.35	0
303	Color	Joe Wright	256.0	111.0	456.0	394.0	Cara Delevingne	20000.0	3.496482e+07	Adventure|Family|Fantasy	...	186.0	English	USA	PG	1.500000e+08	2015.0	548.0	5.8	2.35	24000
389	Color	Josh Trank	369.0	100.0	128.0	78.0	Reg E. Cathey	596.0	5.611422e+07	Action|Adventure|Sci-Fi	...	695.0	English	USA	PG-13	1.200000e+08	2015.0	360.0	4.3	2.35	41000
5 rows × 28 columns

duplicated_rows_imdb_link = movies_df[movies_df.duplicated(['movie_imdb_link'])]
duplicated_rows_imdb_link.shape
(124, 28)
movies_df.shape
(5043, 28)
duplicated_rows_df.index
Int64Index([ 137,  187,  204,  303,  389,  395,  590,  656,  794, 1220, 1305,
            1449, 2169, 2292, 2472, 2493, 2533, 2562, 2568, 2619, 2771, 2777,
            2798, 2971, 3117, 3345, 3452, 3480, 3729, 3900, 3915, 4182, 4226,
            4282, 4313, 4408, 4565, 4573, 4631, 4769, 4882, 4927, 4942, 4950,
            4951],
           dtype='int64')
movies_df.drop(duplicated_rows_df.index,inplace=True)
movies_df.shape
(4998, 28)
## Binning the numerical variables (Converting Numerical to Categorical variables)

op_labels = ['poor','moderate','good']

category_bin = [0.,4.,7.,10.]

movies_df['imdb_labels'] = pd.cut(movies_df['imdb_score'],bins=category_bin,labels=op_labels)
movies_df[['movie_title','imdb_score','imdb_labels']].head()
movie_title	imdb_score	imdb_labels
0	Avatar	7.9	good
1	Pirates of the Caribbean: At World's End	7.1	good
2	Spectre	6.8	moderate
3	The Dark Knight Rises	8.5	good
4	Star Wars: Episode VII - The Force Awakens  ...	7.1	good
movies_df['imdb_labels'].value_counts()
moderate    3249
good        1577
poor         172
Name: imdb_labels, dtype: int64
Checking and Managing Outliers of Data
sns.boxplot(movies_df['facenumber_in_poster'])
C:\Users\Abhishek\anaconda3\lib\site-packages\seaborn\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
<AxesSubplot:xlabel='facenumber_in_poster'>

sns.boxplot(movies_df['facenumber_in_poster'], color = 'red')
C:\Users\Abhishek\anaconda3\lib\site-packages\seaborn\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
<AxesSubplot:xlabel='facenumber_in_poster'>

movies_df[['movie_title','facenumber_in_poster']].iloc[movies_df['facenumber_in_poster'].argmax()]
movie_title             500 Days of Summer 
facenumber_in_poster                   43.0
Name: 3468, dtype: object
movies_df[['movie_title','budget']].iloc[movies_df['budget'].argmax()]
movie_title        The Host 
budget         12215500000.0
Name: 2988, dtype: object
movies_df['facenumber_in_poster'].fillna(value=movies_df['facenumber_in_poster'].mean(),inplace=True)
def outlier_treatment(datacolumn):
    sorted(datacolumn)
    Q1,Q3 = np.percentile(datacolumn,[25,75])
    IQR = Q3- Q1
    lower_range = Q1 - (1.5*IQR)
    upper_range = Q3 + (1.5*IQR)
    return lower_range,upper_range
lower,upper = outlier_treatment(movies_df['facenumber_in_poster'].values)
lower
-3.0
upper
5.0
movies_df[(movies_df['facenumber_in_poster'] < lower) | (movies_df['facenumber_in_poster'] > upper)]
color	director_name	num_critic_for_reviews	duration	director_facebook_likes	actor_3_facebook_likes	actor_2_name	actor_1_facebook_likes	gross	genres	...	language	country	content_rating	budget	title_year	actor_2_facebook_likes	imdb_score	aspect_ratio	movie_facebook_likes	imdb_labels
23	Color	Peter Jackson	509.0	186.0	0.0	773.0	Adam Brown	5000.0	2.583554e+08	Adventure|Fantasy	...	English	USA	PG-13	225000000.0	2013.0	972.0	7.9	2.35	83000	good
47	Color	Bryan Singer	539.0	149.0	0.0	20000.0	Peter Dinklage	34000.0	2.339150e+08	Action|Adventure|Fantasy|Sci-Fi|Thriller	...	English	USA	PG-13	200000000.0	2014.0	22000.0	8.0	2.35	82000	good
65	Color	Bryan Singer	396.0	144.0	0.0	1000.0	Michael Fassbender	34000.0	1.549851e+08	Action|Adventure|Sci-Fi	...	English	USA	PG-13	178000000.0	2016.0	13000.0	7.3	2.35	54000	good
73	Color	David Ayer	418.0	123.0	452.0	329.0	Robin Atkin Downes	10000.0	1.610872e+08	Action|Adventure|Comedy|Sci-Fi	...	English	USA	PG-13	175000000.0	2016.0	336.0	6.9	2.35	80000	moderate
134	Color	Tim Burton	526.0	113.0	13000.0	16000.0	Chloë Grace Moretz	40000.0	7.971168e+07	Comedy|Fantasy|Horror	...	English	USA	PG-13	100000000.0	2012.0	17000.0	6.2	1.85	82000	moderate
...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...	...
4829	Color	Cédric Klapisch	29.0	91.0	82.0	8.0	Zinedine Soualem	75.0	1.652472e+06	Comedy|Romance	...	French	France	R	300000.0	1996.0	9.0	6.9	1.66	166	moderate
4847	Color	Jerome Elston Scott	8.0	98.0	3.0	248.0	Joanna Cassidy	500.0	4.846841e+07	Comedy|Drama|Romance	...	English	USA	R	300000.0	2010.0	317.0	7.2	NaN	7	good
4883	Color	Joel Paul Reisig	1.0	108.0	431.0	3.0	Dana Blackstone	288.0	4.846841e+07	Family	...	English	USA	PG	250000.0	2014.0	96.0	6.6	NaN	71	moderate
4900	Color	David G. Evans	25.0	101.0	0.0	16.0	Chris Thomas	77000.0	2.428241e+06	Drama	...	English	USA	PG-13	200000.0	2010.0	21.0	6.4	NaN	0	moderate
4994	Color	Patrick Meaney	7.0	81.0	3.0	18.0	Greg Aronowitz	26.0	4.846841e+07	Biography|Documentary	...	English	USA	NaN	50000.0	2014.0	20.0	7.4	NaN	83	good
208 rows × 29 columns

movies_df.drop(movies_df[(movies_df['facenumber_in_poster'] < lower) | (movies_df['facenumber_in_poster'] > upper)].index,inplace=True)
movies_df.shape
(4790, 29)
sns.boxplot(movies_df['facenumber_in_poster'])
C:\Users\Abhishek\anaconda3\lib\site-packages\seaborn\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.
  warnings.warn(
<AxesSubplot:xlabel='facenumber_in_poster'>

Standardsization and Normalization
salary_df = pd.read_csv(r"C:\Users\Abhishek\OneDrive\Documents\Data Scientist\Class Notes\Python\Datasets-Sklearn\Salary_Data.csv")
salary_df.head()
YearsExperience	Salary
0	1.1	39343.0
1	1.3	46205.0
2	1.5	37731.0
3	2.0	43525.0
4	2.2	39891.0
sns.scatterplot(x='YearsExperience',y='Salary',data =salary_df)
<AxesSubplot:xlabel='YearsExperience', ylabel='Salary'>

salary_df.describe()
YearsExperience	Salary
count	30.000000	30.000000
mean	5.313333	76003.000000
std	2.837888	27414.429785
min	1.100000	37731.000000
25%	3.200000	56720.750000
50%	4.700000	65237.000000
75%	7.700000	100544.750000
max	10.500000	122391.000000
sns.distplot(salary_df)
C:\Users\Abhishek\anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
<AxesSubplot:ylabel='Density'>

sns.distplot(salary_df['Salary'])
C:\Users\Abhishek\anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
<AxesSubplot:xlabel='Salary', ylabel='Density'>

sns.distplot(salary_df['YearsExperience'])
C:\Users\Abhishek\anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
<AxesSubplot:xlabel='YearsExperience', ylabel='Density'>

salary_df.corr()
YearsExperience	Salary
YearsExperience	1.000000	0.978242
Salary	0.978242	1.000000
Min Max Scaler
from sklearn.preprocessing import MinMaxScaler
mm_scaler = MinMaxScaler()
salary_df_transformed = mm_scaler.fit_transform(salary_df)
type(salary_df_transformed)
numpy.ndarray
salary_df_transformed
array([[0.        , 0.01904087],
       [0.0212766 , 0.1000945 ],
       [0.04255319, 0.        ],
       [0.09574468, 0.06843846],
       [0.11702128, 0.02551382],
       [0.19148936, 0.22337586],
       [0.20212766, 0.26481219],
       [0.22340426, 0.19742499],
       [0.22340426, 0.31554453],
       [0.27659574, 0.229837  ],
       [0.29787234, 0.30105126],
       [0.30851064, 0.21335932],
       [0.30851064, 0.22709662],
       [0.31914894, 0.2285613 ],
       [0.36170213, 0.27616348],
       [0.40425532, 0.35680369],
       [0.42553191, 0.33425467],
       [0.44680851, 0.53575478],
       [0.5106383 , 0.51537916],
       [0.5212766 , 0.66393811],
       [0.60638298, 0.63792818],
       [0.63829787, 0.7151193 ],
       [0.72340426, 0.75089771],
       [0.75531915, 0.89866525],
       [0.80851064, 0.84691708],
       [0.84042553, 0.80145287],
       [0.89361702, 0.93595559],
       [0.90425532, 0.88476258],
       [0.9787234 , 1.        ],
       [1.        , 0.9938696 ]])
new_df = pd.DataFrame(salary_df_transformed,columns=['Experience','Salary'])
new_df.corr()
Experience	Salary
Experience	1.000000	0.978242
Salary	0.978242	1.000000
new_df.head()
Experience	Salary
0	0.000000	0.019041
1	0.021277	0.100094
2	0.042553	0.000000
3	0.095745	0.068438
4	0.117021	0.025514
Z distirbution = ((X-MU)/sigma)

sns.distplot(new_df['Salary'])
C:\Users\Abhishek\anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
<AxesSubplot:xlabel='Salary', ylabel='Density'>

Standard scaler
from sklearn.preprocessing import StandardScaler
ss_scaler = StandardScaler()
ss_transformed_df = ss_scaler.fit_transform(salary_df)
ss_transformed_df
array([[-1.51005294, -1.36011263],
       [-1.43837321, -1.10552744],
       [-1.36669348, -1.419919  ],
       [-1.18749416, -1.20495739],
       [-1.11581443, -1.33978143],
       [-0.86493538, -0.71830716],
       [-0.82909552, -0.58815781],
       [-0.75741579, -0.79981746],
       [-0.75741579, -0.42881019],
       [-0.57821647, -0.69801306],
       [-0.50653674, -0.47433279],
       [-0.47069688, -0.74976858],
       [-0.47069688, -0.70662043],
       [-0.43485702, -0.70201994],
       [-0.29149756, -0.55250402],
       [-0.1481381 , -0.29921736],
       [-0.07645838, -0.37004264],
       [-0.00477865,  0.26285865],
       [ 0.21026054,  0.19885989],
       [ 0.2461004 ,  0.66547573],
       [ 0.53281931,  0.58377993],
       [ 0.6403389 ,  0.82623317],
       [ 0.92705781,  0.93861127],
       [ 1.03457741,  1.40274136],
       [ 1.21377673,  1.24020308],
       [ 1.32129632,  1.09740238],
       [ 1.50049564,  1.51986835],
       [ 1.5363355 ,  1.3590738 ],
       [ 1.78721455,  1.72102849],
       [ 1.85889428,  1.70177321]])
ss_new_df = pd.DataFrame(ss_transformed_df,columns=['YearsExperience','Salary'])
ss_new_df.head()
YearsExperience	Salary
0	-1.510053	-1.360113
1	-1.438373	-1.105527
2	-1.366693	-1.419919
3	-1.187494	-1.204957
4	-1.115814	-1.339781
sns.distplot(ss_new_df['Salary'])
C:\Users\Abhishek\anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
<AxesSubplot:xlabel='Salary', ylabel='Density'>

salary_df['YearsExperience'].corr(salary_df['Salary'])
0.9782416184887599
salary_df.corr()
YearsExperience	Salary
YearsExperience	1.000000	0.978242
Salary	0.978242	1.000000
Categorical Standardization
titanic_df = pd.read_csv(r"C:\Users\Abhishek\OneDrive\Documents\Data Scientist\Class Notes\Python\Datasets-Sklearn\Titanic.csv")
titanic_df.head()
PassengerId	Survived	Pclass	Name	Sex	Age	SibSp	Parch	Ticket	Fare	Cabin	Embarked
0	1	0	3	Braund, Mr. Owen Harris	male	22.0	1	0	A/5 21171	7.2500	NaN	S
1	2	1	1	Cumings, Mrs. John Bradley (Florence Briggs Th...	female	38.0	1	0	PC 17599	71.2833	C85	C
2	3	1	3	Heikkinen, Miss. Laina	female	26.0	0	0	STON/O2. 3101282	7.9250	NaN	S
3	4	1	1	Futrelle, Mrs. Jacques Heath (Lily May Peel)	female	35.0	1	0	113803	53.1000	C123	S
4	5	0	3	Allen, Mr. William Henry	male	35.0	0	0	373450	8.0500	NaN	S
titanic_df['Sex'].value_counts()
male      577
female    314
Name: Sex, dtype: int64
titanic_df['Survived'].value_counts()
0    549
1    342
Name: Survived, dtype: int64
One-hot encoding
titanic_df_encoded = pd.get_dummies(titanic_df,columns=['Sex'])
titanic_df_encoded.head()
PassengerId	Survived	Pclass	Name	Age	SibSp	Parch	Ticket	Fare	Cabin	Embarked	Sex_female	Sex_male
0	1	0	3	Braund, Mr. Owen Harris	22.0	1	0	A/5 21171	7.2500	NaN	S	0	1
1	2	1	1	Cumings, Mrs. John Bradley (Florence Briggs Th...	38.0	1	0	PC 17599	71.2833	C85	C	1	0
2	3	1	3	Heikkinen, Miss. Laina	26.0	0	0	STON/O2. 3101282	7.9250	NaN	S	1	0
3	4	1	1	Futrelle, Mrs. Jacques Heath (Lily May Peel)	35.0	1	0	113803	53.1000	C123	S	1	0
4	5	0	3	Allen, Mr. William Henry	35.0	0	0	373450	8.0500	NaN	S	0	1
titanic_df_encoded = pd.get_dummies(titanic_df,columns=['Sex','Embarked'])
titanic_df_encoded.head()
PassengerId	Survived	Pclass	Name	Age	SibSp	Parch	Ticket	Fare	Cabin	Sex_female	Sex_male	Embarked_C	Embarked_Q	Embarked_S
0	1	0	3	Braund, Mr. Owen Harris	22.0	1	0	A/5 21171	7.2500	NaN	0	1	0	0	1
1	2	1	1	Cumings, Mrs. John Bradley (Florence Briggs Th...	38.0	1	0	PC 17599	71.2833	C85	1	0	1	0	0
2	3	1	3	Heikkinen, Miss. Laina	26.0	0	0	STON/O2. 3101282	7.9250	NaN	1	0	0	0	1
3	4	1	1	Futrelle, Mrs. Jacques Heath (Lily May Peel)	35.0	1	0	113803	53.1000	C123	1	0	0	0	1
4	5	0	3	Allen, Mr. William Henry	35.0	0	0	373450	8.0500	NaN	0	1	0	0	1
Label Encoding
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
titanic_df['Encoded Gender'] = encoder.fit_transform(titanic_df['Sex'])
titanic_df.head()
PassengerId	Survived	Pclass	Name	Sex	Age	SibSp	Parch	Ticket	Fare	Cabin	Embarked	Encoded Gender
0	1	0	3	Braund, Mr. Owen Harris	male	22.0	1	0	A/5 21171	7.2500	NaN	S	1
1	2	1	1	Cumings, Mrs. John Bradley (Florence Briggs Th...	female	38.0	1	0	PC 17599	71.2833	C85	C	0
2	3	1	3	Heikkinen, Miss. Laina	female	26.0	0	0	STON/O2. 3101282	7.9250	NaN	S	0
3	4	1	1	Futrelle, Mrs. Jacques Heath (Lily May Peel)	female	35.0	1	0	113803	53.1000	C123	S	0
4	5	0	3	Allen, Mr. William Henry	male	35.0	0	0	373450	8.0500	NaN	S	1
titanic_df['Encoded Embarked'] = encoder.fit_transform(titanic_df['Embarked'])
titanic_df.head()
PassengerId	Survived	Pclass	Name	Sex	Age	SibSp	Parch	Ticket	Fare	Cabin	Embarked	Encoded Gender	Encoded Embarked
0	1	0	3	Braund, Mr. Owen Harris	male	22.0	1	0	A/5 21171	7.2500	NaN	S	1	2
1	2	1	1	Cumings, Mrs. John Bradley (Florence Briggs Th...	female	38.0	1	0	PC 17599	71.2833	C85	C	0	0
2	3	1	3	Heikkinen, Miss. Laina	female	26.0	0	0	STON/O2. 3101282	7.9250	NaN	S	0	2
3	4	1	1	Futrelle, Mrs. Jacques Heath (Lily May Peel)	female	35.0	1	0	113803	53.1000	C123	S	0	2
4	5	0	3	Allen, Mr. William Henry	male	35.0	0	0	373450	8.0500	NaN	S	1	2
Model Building
Regression

salary_df.shape
(30, 2)
salary_df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 30 entries, 0 to 29
Data columns (total 2 columns):
 #   Column           Non-Null Count  Dtype  
---  ------           --------------  -----  
 0   YearsExperience  30 non-null     float64
 1   Salary           30 non-null     float64
dtypes: float64(2)
memory usage: 608.0 bytes
salary_df.dropna(inplace= True)
salary_df.shape
(30, 2)
from sklearn.preprocessing import StandardScaler
ss_scaler = StandardScaler()
final_df = ss_scaler.fit_transform(salary_df)
type(final_df)
numpy.ndarray
final_df = pd.DataFrame(final_df,columns=['Salary','Experience'])
final_df.head()
Salary	Experience
0	-1.510053	-1.360113
1	-1.438373	-1.105527
2	-1.366693	-1.419919
3	-1.187494	-1.204957
4	-1.115814	-1.339781
Model Building Activity
Step1: Separate the Features and the Target

X = final_df.iloc[:,1]
y = final_df.iloc[:,0]
rules of regression in SK learn

Features and Target should be in the form of ndarray
Features must be in 2d array and Target should be 2d.
X = final_df.iloc[:,1].values
y = final_df.iloc[:,0].values
type(X)
numpy.ndarray
X.shape
(30,)
X = X.reshape(30,1)
X.shape
(30, 1)
type(y)
numpy.ndarray
y.shape
(30,)
y= y.reshape(30,1)
y.shape
(30, 1)
Step2: Create the Training and the Testing data
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=10)
X_train.shape
(21, 1)
X_test.shape
(9, 1)
y_train.shape
(21, 1)
y_test.shape
(9, 1)
X_train
array([[-1.10552744],
       [ 0.66547573],
       [-0.55250402],
       [ 0.19885989],
       [-0.58815781],
       [-0.74976858],
       [ 1.40274136],
       [ 1.24020308],
       [ 1.72102849],
       [ 0.93861127],
       [-0.47433279],
       [ 1.51986835],
       [ 1.70177321],
       [-0.42881019],
       [ 1.09740238],
       [-0.37004264],
       [ 0.26285865],
       [-1.36011263],
       [-0.29921736],
       [-1.33978143],
       [-0.69801306]])
Build the Model
from sklearn.linear_model import LinearRegression
model = LinearRegression()
model.fit(X_train,y_train)
LinearRegression()
model.coef_
array([[0.98692205]])
model.intercept_
array([-0.01778883])
Training Accuracy

model.score(X_train,y_train)
0.9505319424191245
Testing Accuracy

model.score(X_test,y_test)
0.9689191689613381
Step4 Evaluation of the Model
from sklearn.metrics import r2_score,mean_squared_error
y_preds = model.predict(X_test)
Higher the r2 Score better the model

r2_score(y_test,y_preds)
0.9689191689613381
Lower the RMSE, better will be model

np.sqrt(mean_squared_error(y_test,y_preds))
0.1602835757549388
Classification Model
titanic_df.shape
(891, 14)
titanic_df.head()
PassengerId	Survived	Pclass	Name	Sex	Age	SibSp	Parch	Ticket	Fare	Cabin	Embarked	Encoded Gender	Encoded Embarked
0	1	0	3	Braund, Mr. Owen Harris	male	22.0	1	0	A/5 21171	7.2500	NaN	S	1	2
1	2	1	1	Cumings, Mrs. John Bradley (Florence Briggs Th...	female	38.0	1	0	PC 17599	71.2833	C85	C	0	0
2	3	1	3	Heikkinen, Miss. Laina	female	26.0	0	0	STON/O2. 3101282	7.9250	NaN	S	0	2
3	4	1	1	Futrelle, Mrs. Jacques Heath (Lily May Peel)	female	35.0	1	0	113803	53.1000	C123	S	0	2
4	5	0	3	Allen, Mr. William Henry	male	35.0	0	0	373450	8.0500	NaN	S	1	2
titanic_df.columns
Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',
       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked', 'Encoded Gender',
       'Encoded Embarked'],
      dtype='object')
final_df = titanic_df[['Survived','Pclass','Sex','Age','Fare','Embarked']]
final_df.head()
Survived	Pclass	Sex	Age	Fare	Embarked
0	0	3	male	22.0	7.2500	S
1	1	1	female	38.0	71.2833	C
2	1	3	female	26.0	7.9250	S
3	1	1	female	35.0	53.1000	S
4	0	3	male	35.0	8.0500	S
final_df_encoded = pd.get_dummies(final_df,columns=['Sex','Embarked'])
final_df_encoded.head()
Survived	Pclass	Age	Fare	Sex_female	Sex_male	Embarked_C	Embarked_Q	Embarked_S
0	0	3	22.0	7.2500	0	1	0	0	1
1	1	1	38.0	71.2833	1	0	1	0	0
2	1	3	26.0	7.9250	1	0	0	0	1
3	1	1	35.0	53.1000	1	0	0	0	1
4	0	3	35.0	8.0500	0	1	0	0	1
final_df_encoded.dropna(inplace= True)
X = final_df_encoded.iloc[:,1:]
X.head()
Pclass	Age	Fare	Sex_female	Sex_male	Embarked_C	Embarked_Q	Embarked_S
0	3	22.0	7.2500	0	1	0	0	1
1	1	38.0	71.2833	1	0	1	0	0
2	3	26.0	7.9250	1	0	0	0	1
3	1	35.0	53.1000	1	0	0	0	1
4	3	35.0	8.0500	0	1	0	0	1
y = final_df_encoded['Survived'].values
type(X)
pandas.core.frame.DataFrame
X.shape
(714, 8)
y.shape
(714,)
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size =0.3,random_state=27)
X_train.shape
(499, 8)
X_test.shape
(215, 8)
from sklearn.linear_model import LogisticRegression
log_reg_model = LogisticRegression()
log_reg_model.fit(X_train,y_train)
LogisticRegression()
log_reg_model.score(X_train,y_train)
0.8176352705410822
log_reg_model.score(X_test,y_test)
0.7441860465116279
y_preds_log_reg = log_reg_model.predict(X_test)
from sklearn.metrics import classification_report,confusion_matrix
print(classification_report(y_test,y_preds_log_reg))
              precision    recall  f1-score   support

           0       0.75      0.82      0.78       119
           1       0.74      0.66      0.70        96

    accuracy                           0.74       215
   macro avg       0.74      0.74      0.74       215
weighted avg       0.74      0.74      0.74       215

confusion_matrix(y_test,y_preds_log_reg)
array([[97, 22],
       [33, 63]], dtype=int64)
housing_df = pd.read_csv(r'C:\Users\Abhishek\OneDrive\Documents\Data Scientist\Class Notes\Python\Datasets\housing_prices.csv')
housing_df.shape
(1460, 81)
housing_df.columns
Index(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',
       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',
       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType',
       'HouseStyle', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd',
       'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType',
       'MasVnrArea', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',
       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',
       'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating',
       'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF',
       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',
       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',
       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType',
       'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual',
       'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',
       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'PoolQC',
       'Fence', 'MiscFeature', 'MiscVal', 'MoSold', 'YrSold', 'SaleType',
       'SaleCondition', 'SalePrice'],
      dtype='object')
Histogram
sns.distplot(housing_df['LotArea'])
C:\Users\Abhishek\anaconda3\lib\site-packages\seaborn\distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
  warnings.warn(msg, FutureWarning)
<AxesSubplot:xlabel='LotArea', ylabel='Density'>

Observations:

The data is highly skewed
There are peope with higher lot area for their houses compared to normal people
Bar Graph
plot = sns.countplot(x='Exterior1st',data=housing_df)

plot = sns.countplot(x='Exterior1st', data=housing_df)
plot.set_xticklabels(plot.get_xticklabels(),rotation=90)
[Text(0, 0, 'VinylSd'),
 Text(1, 0, 'MetalSd'),
 Text(2, 0, 'Wd Sdng'),
 Text(3, 0, 'HdBoard'),
 Text(4, 0, 'BrkFace'),
 Text(5, 0, 'WdShing'),
 Text(6, 0, 'CemntBd'),
 Text(7, 0, 'Plywood'),
 Text(8, 0, 'AsbShng'),
 Text(9, 0, 'Stucco'),
 Text(10, 0, 'BrkComm'),
 Text(11, 0, 'AsphShn'),
 Text(12, 0, 'Stone'),
 Text(13, 0, 'ImStucc'),
 Text(14, 0, 'CBlock')]

Observation: 1.People are using Vinylsd Material as the exterior1st for their houses

Bi variate Analysis
Scatter
sns.scatterplot(x='LotArea', y='SalePrice',data = housing_df)
<AxesSubplot:xlabel='LotArea', ylabel='SalePrice'>

housing_df['LotArea'].corr(housing_df['SalePrice'])
0.2638433538714056
Observations:

The lot area is linerally related to Sale price. ( If lot area increases the sale price will increase too)
Plot Multiple Graphs
sf_columns = [col_name for col_name in housing_df.columns if 'SF' in col_name]
sf_columns
['BsmtFinSF1',
 'BsmtFinSF2',
 'BsmtUnfSF',
 'TotalBsmtSF',
 '1stFlrSF',
 '2ndFlrSF',
 'LowQualFinSF',
 'WoodDeckSF',
 'OpenPorchSF']
len(sf_columns)
9
fig,axis = plt.subplots(nrows=3,ncols=3,figsize =(10,10))

fig,axis = plt.subplots(nrows=3,ncols=3,figsize =(10,10))

for i in range (0,len(sf_columns)):
    rows = i//3
    cols = i%3
    ax = axis[rows,cols]
    plot = sns.scatterplot(x=sf_columns[i],y='SalePrice',data=housing_df,ax=ax)

Observation:

1st floor Sf is having good relationship with target price
Preparing graphs for Aggregated Data
housing_df['Exterior1st'].value_counts()
VinylSd    515
HdBoard    222
MetalSd    220
Wd Sdng    206
Plywood    108
CemntBd     61
BrkFace     50
WdShing     26
Stucco      25
AsbShng     20
BrkComm      2
Stone        2
AsphShn      1
ImStucc      1
CBlock       1
Name: Exterior1st, dtype: int64
top3_exterior = housing_df['Exterior1st'].value_counts().head(3)
top3_exterior = list(top3_exterior.index)
type(top3_exterior)
list
top3_exterior
['VinylSd', 'HdBoard', 'MetalSd']
housing_df['Exterior_group_new'] = np.where(housing_df['Exterior1st'].isin(top3_exterior),housing_df['Exterior1st'],'Others')
housing_df['Exterior_group_new'].value_counts()
VinylSd    515
Others     503
HdBoard    222
MetalSd    220
Name: Exterior_group_new, dtype: int64
sns.countplot(x='Exterior_group_new',data=housing_df)
<AxesSubplot:xlabel='Exterior_group_new', ylabel='count'>

housing_df['YearBuilt'].head()
0    2003
1    1976
2    2001
3    1915
4    2000
Name: YearBuilt, dtype: int64
housing_df['House_Type'] = np.where(housing_df['YearBuilt']> 2000, 'New','Old')
housing_df['House_Type'].value_counts()
Old    1096
New     364
Name: House_Type, dtype: int64
Preferance of exterior materials between house types
housing_df.groupby(['Exterior_group_new','House_Type']).agg({'SalePrice':['count','mean']})
SalePrice
count	mean
Exterior_group_new	House_Type		
HdBoard	New	1	198500.000000
Old	221	162917.167421
MetalSd	New	19	233826.684211
Old	201	141443.641791
Others	New	35	308898.000000
Old	468	158514.955128
VinylSd	New	309	238043.229773
Old	206	177267.407767
Observations:

New houses prefer VinylSd material
MetalSd & HDboaerd are not preferred by new house types
sns.countplot(x='House_Type', data = housing_df,hue='Exterior_group_new')
<AxesSubplot:xlabel='House_Type', ylabel='count'>

sns.heatmap(housing_df.corr())
<AxesSubplot:>

sf_cols_heatmap = sns.heatmap(housing_df[sf_columns].corr())

sf_cols_heatmap = sns.heatmap(housing_df[sf_columns].corr(),annot=True)

sf_columns.append('SalePrice')
sf_columns
['BsmtFinSF1',
 'BsmtFinSF2',
 'BsmtUnfSF',
 'TotalBsmtSF',
 '1stFlrSF',
 '2ndFlrSF',
 'LowQualFinSF',
 'WoodDeckSF',
 'OpenPorchSF',
 'SalePrice']
sf_cols_heatmap = sns.heatmap(housing_df[sf_columns].corr(),annot=True)

 
